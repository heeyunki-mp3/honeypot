{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SMALL_VALUE=0.00001\n",
    "ENTROPY_THRESHOLD = 0.001\n",
    "MIN_STEP=2\n",
    "training_data = pd.read_csv(\"./data/training_data.csv\")\n",
    "testing_data = pd.read_csv('./data/testing_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_command_string(command_str):\n",
    "    # Convert the string representation of the list to an actual list\n",
    "    return ast.literal_eval(command_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in testing_data.iterrows():\n",
    "    if len(parse_command_string(row['commands'])) < MIN_STEP:\n",
    "        testing_data.drop(index, inplace=True)\n",
    "testing_data.index = range(len(testing_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=set()\n",
    "for i in range(len(testing_data)):\n",
    "    temp.add(len(parse_command_string(testing_data['commands'][i])))\n",
    "MAX_STEP = max(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construction of Markov Chain\n",
    "\n",
    "def create_markov_chain(commands, counts):\n",
    "    markov_chain = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for command, count in zip(commands, counts):\n",
    "        # Add a transition from 'START' to the first state of the command\n",
    "        markov_chain[\"START\"][command[0]] += count\n",
    "        for (current_state, next_state) in zip(command[:-1], command[1:]):\n",
    "            markov_chain[current_state][next_state] += count\n",
    "\n",
    "        markov_chain[command[-1]][\"END\"] += count\n",
    "\n",
    "\n",
    "    return markov_chain\n",
    "\n",
    "\n",
    "def _create_transition_matrix(markov_chain):\n",
    "    \"\"\"\n",
    "    Create a transition matrix from the given Markov chain.\n",
    "    Normalize the matrix so that rows sum to 1.\n",
    "    \"\"\"\n",
    "    states = list(markov_chain.keys())\n",
    "    transition_matrix = pd.DataFrame(0, index=states, columns=states)\n",
    "    \n",
    "    for current_state, transitions in markov_chain.items():\n",
    "        total_transitions = sum(transitions.values())\n",
    "        if total_transitions > 0:\n",
    "            for next_state, count in transitions.items():\n",
    "                transition_matrix.at[current_state, next_state] = count\n",
    "    transition_matrix = transition_matrix.fillna(0)\n",
    "    \n",
    "    transition_matrix=transition_matrix.div(transition_matrix.sum(axis=1), axis=0)\n",
    "    return transition_matrix\n",
    "\n",
    "def draw_markov_chain(markov_chain):\n",
    "    \"\"\"\n",
    "    Draw the Markov chain using networkx and matplotlib.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    for current_state, transitions in markov_chain.items():\n",
    "        for next_state, count in transitions.items():\n",
    "            G.add_edge(current_state, next_state, weight=count)\n",
    "            \n",
    "    pos = nx.spring_layout(G, k=2, iterations=50)  # Adjust the layout parameters for more spacing\n",
    "    \n",
    "    plt.figure(figsize=(13, 13))  # Increase figure size\n",
    "    edge_labels = {(u, v): d['weight'] for u, v, d in G.edges(data=True)}\n",
    "    \n",
    "    nx.draw(G, pos, with_labels=True, node_size=3000, node_color=\"skyblue\", font_size=12, font_weight=\"bold\", arrows=True)\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n",
    "    \n",
    "    plt.title(\"Markov Chain\")\n",
    "    plt.show()\n",
    "\n",
    "def draw_heatmap(transition_matrix):\n",
    "    \"\"\"\n",
    "    Draw a heatmap of the transition matrix using seaborn with zero values colored green.\n",
    "    \"\"\"\n",
    "    # Create a custom colormap that maps zero to green\n",
    "    colors = [(0, \"green\"), (1, \"white\")]  # Map 0 to green and 1 to white\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors, N=256)\n",
    "    \n",
    "    plt.figure(figsize=(3, 3))\n",
    "    # Apply the custom colormap to the heatmap\n",
    "    sns.heatmap(transition_matrix, annot=True, cmap=cmap, fmt=\".2f\", vmin=0, vmax=1)\n",
    "    plt.title(\"Transition Matrix Heatmap\")\n",
    "    plt.show()\n",
    "    \n",
    "def get_transition_matrix(label_value):\n",
    "    # Filter rows based on the label value\n",
    "    df_filtered = training_data[training_data['label'] == label_value].copy()\n",
    "\n",
    "    # Parse the command column\n",
    "    df_filtered.loc[:, 'command'] = df_filtered['command'].apply(parse_command_string)\n",
    "\n",
    "    # Generate Markov chain from the commands\n",
    "    all_commands = df_filtered['command'].tolist()\n",
    "    all_counts = df_filtered['total count'].tolist()\n",
    "\n",
    "    markov_chain = create_markov_chain(all_commands, all_counts)\n",
    "    transition_matrix = _create_transition_matrix(markov_chain)\n",
    "    \n",
    "    return transition_matrix\n",
    "\n",
    "def transition_probability(transition_matrix, start_state, end_state):\n",
    "    \"\"\"\n",
    "    Calculate the probability of transitioning from one state to another in a single step.\n",
    "    If either state is not found or the transition probability is 0, return 0.00001.\n",
    "\n",
    "    Parameters:\n",
    "    - transition_matrix (pd.DataFrame): Transition matrix as a pandas DataFrame.\n",
    "    - start_state (str or int): The starting state.\n",
    "    - end_state (str or int): The ending state.\n",
    "\n",
    "    Returns:\n",
    "    - float: Probability of transitioning from start_state to end_state in one step,\n",
    "             or 0.00001 if either state is not found or the probability is 0.\n",
    "    \"\"\"\n",
    "    # Return 0.00001 if start or end state is not in the transition matrix\n",
    "    if start_state not in transition_matrix.index or end_state not in transition_matrix.columns:\n",
    "        return SMALL_VALUE\n",
    "\n",
    "    # Retrieve the probability directly\n",
    "    start_idx = transition_matrix.index.get_loc(start_state)\n",
    "    end_idx = transition_matrix.columns.get_loc(end_state)\n",
    "    probability = transition_matrix.iloc[start_idx, end_idx]\n",
    "\n",
    "    # Return 0.00001 if the probability is 0\n",
    "    return probability if probability != 0 else SMALL_VALUE\n",
    "\n",
    "def prob_sequence_in_cluster(transition_matrix, sequence):\n",
    "    curr_prob = 1\n",
    "    for i in range(len(sequence)-1):\n",
    "        curr_prob *= transition_probability(transition_matrix, sequence[i],sequence[i+1])\n",
    "    return curr_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_cluster = list(set(training_data['label']))\n",
    "\n",
    "cluster_to_matrix = dict()\n",
    "for i in possible_cluster:\n",
    "    cluster_to_matrix[i] = get_transition_matrix(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_dict = dict()\n",
    "total_count = sum(training_data['total count'])\n",
    "    \n",
    "for i in possible_cluster:\n",
    "    prior_dict[i]=sum(training_data.loc[training_data['label'] == i]['total count'])/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: currently this is \"option 1\" from prof. dalal's note. change if needed.\n",
    "def prior(i):\n",
    "    return prior_dict[i] # Option 2\n",
    "    #return 1/len(possible_cluster) # Option 1\n",
    "\n",
    "def p(sequence):\n",
    "    ret_dict = dict()\n",
    "    ret_list = list()\n",
    "    total = 0\n",
    "    for i in possible_cluster:\n",
    "        curr = prob_sequence_in_cluster(cluster_to_matrix[i], sequence) * prior(i)\n",
    "        ret_dict[i]= curr\n",
    "        total += curr\n",
    "    \n",
    "    for i in possible_cluster:\n",
    "        ret_dict[i] = ret_dict[i] / total\n",
    "        ret_list.append(ret_dict[i])\n",
    "\n",
    "    return (ret_dict, possible_cluster, ret_list)\n",
    "\n",
    "def run_n_steps(sequence, steps, append_start=False):\n",
    "    seq = sequence[:steps]\n",
    "    if append_start:\n",
    "        seq.insert(0, \"START\")\n",
    "    return p(seq)\n",
    "\n",
    "def ent(prob):\n",
    "    #computes entropy of a prob vector-\n",
    "    #prob has to be non-negative and adds up to 1.\n",
    "    prob=np.array(prob)\n",
    "    prob=prob[np.where(prob>0)]\n",
    "    return(-np.dot(prob,np.log2(prob)))\n",
    "\n",
    "def prob_entropy(prob,categories):\n",
    "  px=np.array(prob)\n",
    "  px=px/sum(px)\n",
    "  # Create a bar chart and computer entropy\n",
    "  plt.figure(figsize=(4,2))\n",
    "  plt.bar(categories, px)\n",
    "  plt.xlabel('Categories')\n",
    "  plt.ylabel('Probabilities')\n",
    "  plt.title('Distribution')\n",
    "  # Display the chart\n",
    "  plt.show()\n",
    "  return(ent(prob))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.01179450582130521"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=parse_command_string(testing_data['commands'][2])\n",
    "d, cat, prob = run_n_steps(test,4, False)\n",
    "entropy=prob_entropy(prob, cat)\n",
    "\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_over_time = dict()\n",
    "group_over_time = dict()\n",
    "right_value_moment = dict()\n",
    "ground_truth_dict = dict()\n",
    "for session in list(testing_data[\"session\"]):\n",
    "    entropy_over_time[session] = list()\n",
    "    right_value_moment[session] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth(append_start=True):\n",
    "    sessions = list()\n",
    "    sequences = list()\n",
    "    ground_truths = list()\n",
    "    entropies = list()\n",
    "    \n",
    "    for i in range(len(testing_data)):\n",
    "        test=parse_command_string(testing_data['commands'][i])\n",
    "        \n",
    "        d, cat, prob = run_n_steps(test,len(test), append_start=append_start)\n",
    "        entropy=ent(prob)\n",
    "        \n",
    "\n",
    "        v = list(d.values())\n",
    "        k = list(d.keys())\n",
    "        ground_truth = k[v.index(max(v))]\n",
    "        \n",
    "        session = testing_data['session'][i]\n",
    "        \n",
    "        sessions.append(session)\n",
    "        sequences.append(test)\n",
    "        ground_truths.append(ground_truth)\n",
    "        entropies.append(entropy)\n",
    "        \n",
    "        ground_truth_dict[session] = ground_truth\n",
    "\n",
    "        if entropy > ENTROPY_THRESHOLD:\n",
    "            print(f\"Session {testing_data['session'][i]} has high entropy of {entropy}\")\n",
    "    df = pd.DataFrame()\n",
    "    df[\"session\"] = sessions\n",
    "    df[\"sequence\"] = sequences\n",
    "    df[\"ground_truth\"] = ground_truths\n",
    "    df[\"entropy\"] = entropies\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 0746247aa68a has high entropy of 0.11868219694237274\n",
      "Session 0892671fbc80 has high entropy of 0.11868219694237274\n",
      "Session 102f1d2958d1 has high entropy of 0.11868219694237274\n",
      "Session 1e1f099bcb9b has high entropy of 0.11868219694237274\n",
      "Session 2249f30eb4d1 has high entropy of 0.42183645828036204\n",
      "Session 460b7cfa2463 has high entropy of 0.42183645828036204\n",
      "Session 6f3aac271eca has high entropy of 0.42183645828036204\n",
      "Session 78a7f4cc8125 has high entropy of 0.11868219694237274\n",
      "Session 96b5f84ccdc7 has high entropy of 0.42183645828036204\n",
      "Session c5cc9ad77e1c has high entropy of 0.42183645828036204\n",
      "Session d2c833552ddf has high entropy of 0.11868219694237243\n",
      "Session f6ded7e5b6a8 has high entropy of 0.42183645828036204\n"
     ]
    }
   ],
   "source": [
    "grounds = get_ground_truth(True)\n",
    "grounds.to_csv(\"./data/ground_truth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_step(step=2, append_start=True):\n",
    "    \n",
    "    for i in range(len(testing_data)):\n",
    "        test=parse_command_string(testing_data['commands'][i])\n",
    "        if len(test)<step:\n",
    "            continue\n",
    "        \n",
    "        d, cat, prob = run_n_steps(test,step, append_start=append_start)\n",
    "        entropy=ent(prob)\n",
    "        \n",
    "\n",
    "        \n",
    "        # if entropy > ENTROPY_THRESHOLD:\n",
    "        #     print(f\"Session {testing_data['session'][i]} has entropy of {entropy}\")\n",
    "        #     print(test)\n",
    "        #     print(d)\n",
    "        #     print(\"==================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(append_start=True):\n",
    "    for session in list(testing_data[\"session\"]):\n",
    "        entropy_over_time[session] = list()\n",
    "        group_over_time[session] = list()\n",
    "\n",
    "        \n",
    "        right_value_moment[session] = -1\n",
    "        \n",
    "    list_not_matched = list()\n",
    "    \n",
    "    debug = False\n",
    "    for step in range(1,MAX_STEP+1): \n",
    "        print(f\"Runing steps of {step} out of {MAX_STEP}\")\n",
    "        for i in range(len(testing_data)):\n",
    "            session=testing_data['session'][i]\n",
    "            # if session == \"fff9cebbd635\":\n",
    "            #     debug = True\n",
    "            # else:\n",
    "            #     debug = False\n",
    "            \n",
    "            test=parse_command_string(testing_data['commands'][i])\n",
    "            if debug:\n",
    "                print(\"test command\", test, i)\n",
    "                \n",
    "            if len(test)<step:\n",
    "                continue\n",
    "            \n",
    "            d, cat, prob = run_n_steps(test, step, append_start=append_start)\n",
    "            if debug:\n",
    "                print(d)\n",
    "                print(prob)\n",
    "\n",
    "            entropy=ent(prob) \n",
    "            v = list(d.values())\n",
    "            k = list(d.keys())\n",
    "            committed_group = k[v.index(max(v))]\n",
    "\n",
    "            if debug:\n",
    "                print(\"entropy\", entropy)\n",
    "                print(\"committed to\", committed_group)\n",
    "            \n",
    "            if ground_truth_dict[session] != committed_group:\n",
    "                list_not_matched.append((step, entropy))\n",
    "            \n",
    "            \n",
    "            if ground_truth_dict[session] == committed_group and right_value_moment[session] == -1:\n",
    "                right_value_moment[session] = step\n",
    "            group_over_time[session].append(committed_group)\n",
    "            entropy_over_time[session].append(entropy)\n",
    "            if debug:\n",
    "                print(\"dictionary\", entropy_over_time[session])\n",
    "    return (right_value_moment, entropy_over_time, list_not_matched, group_over_time)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runing steps of 1 out of 25\n",
      "Runing steps of 2 out of 25\n",
      "Runing steps of 3 out of 25\n",
      "Runing steps of 4 out of 25\n",
      "Runing steps of 5 out of 25\n",
      "Runing steps of 6 out of 25\n",
      "Runing steps of 7 out of 25\n",
      "Runing steps of 8 out of 25\n",
      "Runing steps of 9 out of 25\n",
      "Runing steps of 10 out of 25\n",
      "Runing steps of 11 out of 25\n",
      "Runing steps of 12 out of 25\n",
      "Runing steps of 13 out of 25\n",
      "Runing steps of 14 out of 25\n",
      "Runing steps of 15 out of 25\n",
      "Runing steps of 16 out of 25\n",
      "Runing steps of 17 out of 25\n",
      "Runing steps of 18 out of 25\n",
      "Runing steps of 19 out of 25\n",
      "Runing steps of 20 out of 25\n",
      "Runing steps of 21 out of 25\n",
      "Runing steps of 22 out of 25\n",
      "Runing steps of 23 out of 25\n",
      "Runing steps of 24 out of 25\n",
      "Runing steps of 25 out of 25\n"
     ]
    }
   ],
   "source": [
    "rvm, eot, lnm, got = run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "091218400063 10\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "0a60c5b06bca 6\n",
      "[3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "0cd946a465b4 10\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "12e0e10152a1 10\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "2149b016aa3f 6\n",
      "[3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "2249f30eb4d1 3\n",
      "[0, 0, 5, 5, 5]\n",
      "=======================\n",
      "23fb4e8afd47 6\n",
      "[3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "2af0676d1586 10\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "2ccb2b59d59b 10\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "4502907b5eee 10\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "460b7cfa2463 3\n",
      "[0, 0, 5, 5, 5]\n",
      "=======================\n",
      "5e78936e55f6 6\n",
      "[3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "6f3aac271eca 3\n",
      "[0, 0, 5, 5, 5]\n",
      "=======================\n",
      "94e9587d1a87 10\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "96b5f84ccdc7 3\n",
      "[0, 0, 5, 5, 5]\n",
      "=======================\n",
      "97f35ef44c50 6\n",
      "[3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "ab296ff5e2df 10\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "baff530932ce 10\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "bde2165a93ac 6\n",
      "[3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "c5cc9ad77e1c 3\n",
      "[0, 0, 5, 5, 5]\n",
      "=======================\n",
      "cf43d9726a23 10\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "=======================\n",
      "f6ded7e5b6a8 3\n",
      "[0, 0, 5, 5, 5]\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "switched_ones_session = list()\n",
    "\n",
    "for k in rvm.keys():\n",
    "    v=rvm[k]\n",
    "    if v != 1:\n",
    "        switched_ones_session.append(k)\n",
    "        print(k,v)\n",
    "        print(got[k])\n",
    "        print(\"=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 091218400063\n",
      "0 0a60c5b06bca\n",
      "0 0cd946a465b4\n",
      "0 12e0e10152a1\n",
      "0 2149b016aa3f\n",
      "5 2249f30eb4d1\n",
      "0 23fb4e8afd47\n",
      "0 2af0676d1586\n",
      "0 2ccb2b59d59b\n",
      "0 4502907b5eee\n",
      "5 460b7cfa2463\n",
      "0 5e78936e55f6\n",
      "5 6f3aac271eca\n",
      "0 94e9587d1a87\n",
      "5 96b5f84ccdc7\n",
      "0 97f35ef44c50\n",
      "0 ab296ff5e2df\n",
      "0 baff530932ce\n",
      "0 bde2165a93ac\n",
      "5 c5cc9ad77e1c\n",
      "0 cf43d9726a23\n",
      "5 f6ded7e5b6a8\n"
     ]
    }
   ],
   "source": [
    "with open(\"./results/switched_ones.csv\", mode='w', newline='') as file:\n",
    "\n",
    "    header = ['position', 'wrong entropy', 'correct entropy']\n",
    "    writer = csv.DictWriter(file, fieldnames = header)\n",
    "     \n",
    "    # writing data row-wise into the csv file\n",
    "    writer.writeheader()\n",
    "    for s in switched_ones_session:\n",
    "        ground_truth= ground_truth_dict[s]  \n",
    "        print(ground_truth, s) \n",
    "\n",
    "        for i in range(len(eot[s])):\n",
    "            if got[s][i]!= ground_truth:\n",
    "                writer.writerow( {\"position\":i,\n",
    "                                 \"wrong entropy\": eot[s][i]})\n",
    "            else:\n",
    "                 writer.writerow( {\"position\":i,\n",
    "                                 \"correct entropy\": eot[s][i]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum length of lists in the dictionary values\n",
    "max_len = MAX_STEP\n",
    "# Pad lists to ensure all rows have the same number of columns\n",
    "padded_data = {key: value + [''] * (max_len - len(value)) for key, value in entropy_over_time.items()}\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(\"./results/entropy_over_steps.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write each key and its corresponding list to the file\n",
    "    for key, value in padded_data.items():\n",
    "        writer.writerow([key] + value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_value_data = []\n",
    "for key, values in entropy_over_time.items():\n",
    "    for pos, value in enumerate(values):\n",
    "        position_value_data.append([pos, value])\n",
    "\n",
    "# Write to CSV\n",
    "with open(\"./results/entropy_to_be_graphed.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Position', 'Value'])  # Write header\n",
    "    writer.writerows(position_value_data)  # Write data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_value_data = []\n",
    "for key, values in rvm.items():\n",
    "   \n",
    "    position_value_data.append([key, value])\n",
    "\n",
    "# Write to CSV\n",
    "with open(\"./results/right_value_moment.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['session', 'step'])  # Write header\n",
    "    writer.writerows(position_value_data)  # Write data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./results/entropy_bad.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Position', 'Value'])  # Write header\n",
    "    writer.writerows(lnm)  # Write data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
